version: '3.8'
services:
  postgres:
    image: postgres:15
    command: ["postgres", "-c", "shared_preload_libraries=pg_stat_statements", "-c", "pg_stat_statements.max=10000", "-c", "pg_stat_statements.track=all"]
    restart: always
    env_file:
      - .env
    environment:
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB: ${POSTGRES_DB}
    # SECURITY: Removed external port mapping - database only accessible internally
    # ports:
    #   - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/initdb:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 30s
      timeout: 10s
      retries: 3

  minio:
    image: minio/minio:latest
    command: server /data --console-address ":9001"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      # SECURITY: Use secure credentials - avoid exposing in environment
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-admin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-CHANGE_THIS_TO_SECURE_PASSWORD}
    volumes:
      - minio_data:/data

  backend:
    build:
      context: ./server
    ports:
      - "5000:5000"
    volumes:
      - ./server:/app
      - ./uploads:/app/uploads
    env_file:
      - .env
    environment:
      - NODE_ENV=${NODE_ENV}
      - DATABASE_URL=${DATABASE_URL}
      - FILE_STORAGE_PROVIDER=${FILE_STORAGE_PROVIDER}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
      - AWS_REGION=${AWS_REGION}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_S3_ENDPOINT=http://minio:9000
      - AWS_S3_FORCE_PATH_STYLE=true
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5000/health"]
      interval: 30s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 512M

  frontend:
    build:
      context: ./client
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_healthy
    volumes:
      - ./client:/app
      - /app/node_modules
    env_file:
      - .env
    environment:
      - NODE_ENV=${NODE_ENV}

  # Automated daily database backup to S3 / MinIO
  db-backup:
    image: alpine:3.20
    depends_on:
      - postgres
    environment:
      - PGHOST=postgres
      - PGUSER=${POSTGRES_USER}
      - PGPASSWORD=${POSTGRES_PASSWORD}
      - PGDATABASE=${POSTGRES_DB}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
      - AWS_S3_BUCKET=${AWS_S3_BUCKET}
    volumes:
      - pg_backups:/backups
    entrypoint: /bin/sh -c "apk add --no-cache postgresql-client aws-cli && echo '0 2 * * * pg_dump -Fc --no-acl --no-owner -f /backups/$(date +%F).dump && aws s3 cp /backups/$(date +%F).dump s3://${AWS_S3_BUCKET}/db-backups/' > /etc/crontabs/root && crond -f -l 0"

  # Automated file cleanup job
  file-cleanup:
    image: node:20-alpine
    depends_on:
      - postgres
    working_dir: /app
    volumes:
      - ./:/app
    env_file:
      - .env
    entrypoint: /bin/sh -c "npm install && npm run cleanup"
    restart: "no"

  # Loki for log aggregation
  loki:
    image: grafana/loki:3.0.0
    command: -config.file=/etc/loki/loki-config.yml
    ports:
      - "3100:3100"
    volumes:
      - loki_data:/loki
      - ./docker/loki-config.yml:/etc/loki/loki-config.yml

  # Promtail side-car that ships logs to Loki
  promtail:
    image: grafana/promtail:3.0.0
    command: -config.file=/etc/promtail/promtail.yml
    depends_on:
      - loki
    volumes:
      - ./docker/promtail-config.yml:/etc/promtail/promtail.yml
      - postgres_data:/var/lib/postgresql/data:ro
      - ./server/logs:/var/log/smarttaxpro:ro

volumes:
  postgres_data:
  minio_data:
  pg_backups:
  loki_data:
